---
title: "Estudo de Cópulas"
author: "Guilherme Colombo Soares"
output:
  pdf_document: default
  html_notebook: default
  html_document:
    df_print: paged
---

### Introdução

De acordo com Nelsen(1999), copulas podem ser definidas de duas formas: 1) funções que "acoplam" uma distribuição multivariada às suas funções de distribuição marginal unidimensionais. 2) Alternativamente, cópulas são funções de distribuição multivariada cujas marginais unidimensionais são uniformes no intervalo (0,1).

De acordo com Fisher (1997) "Cópulas são de interesse para os estatísticos por duas razões principais: em primeiro lugar, como um meio de estudar medidas de dependência; e em segundo lugar, como ponto de partida para a construção de famílias de distribuições bivariadas."

Funções cópulas são representações flexíveis de distribuições conjuntas e fornecem especificações separadas de distribuições marginais e dependência e nos respondem questões como:

Suponha que temos duas variáveis, $X$ e $Y$, onde $Y$ é uma função não-linear de $X$ mais uma variável aleatória. Além disso, temos uma terceira variável, $Z$, que é a soma de $X$ e $Y$. A pergunta que surge é: qual é a distribuição de $Z$ e como podemos descrever a dependência entre $X$ e $Z$?

Nesse estudo serão utilizadas copulas para estudar a dependecia entre inflação medida por ipca e por igpm. No final, compara-se uma projeção feita por copulas (Vine-Copula) com uma feita por regressão linear.

```{r}
library(readxl)
library(knitr)

data <- read_excel("C:/Users/guilh/Downloads/datacop2.xlsx")
rownames(data) <- c()
data$dolar <- c(NA, diff(data$dolar))
data$juroreal <- c(NA, diff(data$juroreal))
data <- na.omit(data)
kable(head(data))
```

```{r}
typeof(data$ipca)
```

```{r}
library(ggplot2)

ggplot(data, aes(x = ipca)) +
  geom_histogram(binwidth = 0.1, fill = "blue", color = "black") +
  labs(title = "Distribuição de Ipca", x = "Ipca", y = "Frequência")

ggplot(data, aes(x = igpm)) +
  geom_histogram(binwidth = 0.20, fill = "green", color = "black") +
  labs(title = "Distribuição de igpm", x = "igpm", y = "Frequência")

ggplot(data, aes(x = dolar)) +
  geom_histogram(binwidth = 0.05, fill = "red", color = "black") +
  labs(title = "Distribuição de dolar(diff)", x = "dolar", y = "Frequência")

ggplot(data, aes(x = juroreal)) +
  geom_histogram(binwidth = 0.1, fill = "purple", color = "black") +
  labs(title = "Distribuição de juroreal(diff)", x = "juroreal", y = "Frequência")

```

```{r}
ggplot(data, aes(x = ipca, y = igpm)) +
  geom_point() +
  labs(title = "Gráfico de Dispersão", x = "Igpm", y = "Ipca")
```

# Medidas de dependência

As cópulas podem ser utilizadas para captar relações não lineares entre as variaveis, diferente do que é usado comumente em medidas de correlação como o coeficiente de person, para a avaliação das relações entre as variáveis, serão apresentados novas medidas de correlação com base na "concordância" e "discordância" (tradução propria de Nelsen, 1999).

De acordo com Nelsen(1999) ideia de concordancia e discordancia é relacionada a noção de se valores altos de uma varia´vel estão relacionados com valores altos da outra e valores baixos relacionados com valores baixos. Ou seja, deixe $(x_i, y_i)$ e $(x_j, y_j)$ denotarem observações do vetor $(X,Y)$ de variáveis continuas aleatórias. Dizemos que são "concordantes" se $x_i < x_j$ e $y_i < y_j$ ou $x_i > x_j$ e $y_i>y_j$. E "discordantes" se $x_i>x_j$ e $y_i<y_j$ ou viceversa.

## Correlação de Person

A correlação de pearson é uma abordagem linear entre duas variáveis, e é dada da seguinte forma:

$r_{xy}$ = $\frac{\sum(x - \bar{x})(y - \bar{y})}{\sqrt{\sum(x - \bar{x})^2\sum(y - \bar{y})^2}}$

onde $\bar{x}$ e $\bar{y}$ são as médias das variáveis. A correlão de Person então, capta relações lineares.

## $\tau$ de Kendall

Deixe {$(x_1, y_1)$, $(x_2, y_2)$... $(x_n, y_n)$} denotar uma amostra aleatória de n observações do vetor $(X,Y)$ de variáveis aleatórias continuas. Tem-se então ($\frac{n}{2}$) pares distintos $(x_i, y_i)$ e $(x_j, y_j)$ de observações da amostra. Cada par pode ser concordante(c) ou discordante(d). Assim, o $\tau$ de kendall pode ser definido como:

$\tau_{xy}$ = $\frac{(c - d)}{(c+d)}$

Portanto o $\tau$ é a probabilidade de concordancia menos a probabilidade de discordancia de um par $(x_i, y_i)$ e $(x_j, y_j)$ escolhidos aleatóriamente.

Outra formula usada para calcular o $\tau$ em sua versão populacional é:

$\tau_{xy}$= $P[(X_i - X_{i+1})(Y_i - Y_{i+1}) > 0 ]$ - $P[(X_i - X_{i+1})(Y_i - Y_{i+1}) < 0 ]$

## $\rho$ de Spearman

Assim como no $\tau$ de Kendall, o $\rho$ de Spearman também é uma medida de concordancia e discordância. Deixe $(x_1, y_1)$ , $(x_2, y_2)$ e $(x_3, y_3)$ serem 3 vetores aleatorios com a mesma função distribuição conjunta H(com as margens F e G) e uma cópula C. O $\rho$ de Spearman será uma probabilidade de concordancia e discordancia para os vetores $(x_1, y_1)$ e $(x_2, y_3)$. Ou seja, diferente do $\tau$, um par de vetores terá a distribuição H e o outro é independente em seus componentes, o que torna a correlação de Spearman mais sensivel a extremos que a de Kendall.

$\rho_{xy}$ = $3(P[(X_1 - X_2)(Y_1 - Y_3) > 0 ]$ - $P[(X_1 - X_2)(Y_1 - Y_3) < 0 ])$

(O 3 que multiplica a função aparece na formula como uma constante de normalização, ver Nelsen 1999 p. 135)

```{r}
pearson_corr <- cor(data$ipca, data$igpm, method = "pearson")
kendall_corr <- cor(data$ipca, data$igpm, method = "kendall")
spearman_corr <- cor(data$ipca, data$igpm, method = "spearman")

print(paste("Coeficiente de Correlação de Pearson:", pearson_corr))
print(paste("Coeficiente de Correlação de Kendall:", kendall_corr))
print(paste("Coeficiente de Correlação de Spearman:", spearman_corr))

```

### Fundamentos teóricos das cópulas

#### Teorema de Sklar

O teorema de Sklar é um teorema fundamental para a a aplicação de copulas. De acordo com Nelsen(1999) o teorema de sklar elucida as relações entre as distribuições multivariadas e as distribuições marginais.

O **teorema de Sklar** nos diz que: Tome $H$ como uma função de distribuiçao conjunta com margens $F$ e $G$. Então existe uma copula $C$, tal que para todo $x,y$ em $\overline{R} = [-\infty, +\infty]$.

$(1)$ $$ H(x,y) = C(F(x), G(Y))$$ A partir do teorema de Sklar, podemos "ligar" as funções marginais univariadas em uma função multivariada.

A formula (1) nos da uma função de distribuição conjunta em função de duas funções de distribuição univariadas.(1) pode ser invertida para representar copulas em termos da função de distribuição conjunta e a inversa das duas margens, de forma que:

$(2)$$$ C(u,v) = H(F^{-1}(u), G^{-1}(v)) $$ O resultado (2) nos permite construir copulas quando F e G são continuas.

#### Limites de Fréchet-Hoeffding

Outro resultado importante são os **limites de Fréchet-Hoeffding** que nos diz que para toda Copula C, para todo u,v em I: $$ W(u,v) = \max(u+v-1, 0) \leq C(u,v) \leq M(u,v) = \min(u,v) $$

Os **limites de Fréchet-Hoeffding** no permitem saber que:

i)  Se $X$ e $Y$ são variáveis aleatórias com função de distribuição conjunta $H$. Então $H$ é igual ao $W(F(x),G(y))$ se e somente se para todo $(x,y)$ em $\overline{R}$$^2$, ou $P[$X\>x, $Y$ $\leq$ $y$$]$ , ou $P[$X $\leq$x$, Y>y] = 0$ .

ii)E $H$ é igual ao $M(F(x),G(y))$ se e somente se $\min(P[X\leq$$x$, $Y > y$], $P[X$\>$x$, $Y \leq y$]) = 0

#### Modelando cópulas

```{r}
data_normalized <- as.data.frame(scale(data))
head(data_normalized)
```

```{r}
cdf_ipca <- ecdf(data$ipca)

cdf_igpm <- ecdf(data$igpm)

ipca_values <- seq(min(data_normalized$ipca), max(data_normalized$ipca), length.out = 100)
igpm_values <- seq(min(data_normalized$igpm), max(data_normalized$igpm), length.out = 100)


cdf_ipca_values <- cdf_ipca(ipca_values)
cdf_igpm_values <- cdf_igpm(igpm_values)

plot(ipca_values, cdf_ipca_values, type = "l", col = "blue",
     xlab = "ipca", ylab = "Função de Densidade Acumulada",
     main = "Função de Densidade Acumulada para ipca")


lines(igpm_values, cdf_igpm_values, type = "l", col = "red")

legend("bottomright", legend = c("ipca", "igpm"), col = c("blue", "red"), lty = 1)


```

```{r}
ipca_uniform <- pnorm(data_normalized$ipca)
igpm_uniform <- pnorm(data_normalized$igpm)


uniform_df <- data.frame(ipca_uniform , igpm_uniform)


hist(uniform_df$ipca_uniform, main = "Distribuição Uniforme de ipca ", xlab = "Valor Uniformizado")
hist(uniform_df$igpm_uniform, main = "Distribuição Uniforme de igpm", xlab = "Valor Uniformizado")

```

```{r}
ggplot(uniform_df, aes(x = ipca_uniform, y = igpm_uniform)) +
  geom_point() +
  labs(title = "Gráfico de Dispersão", x = "IPCA", y = "IGPM")

```

**Copula Normal**

$$C(u_1,\ldots,u_n) = \boldsymbol{\Phi}_{\boldsymbol{P}}(\Phi^{-1}(u_1),\ldots,\Phi^{-1}(u_n))$$

$$c(u_1,\ldots,u_n) = \frac{1}{\sqrt{\textrm{det}(\boldsymbol{P})}}\textrm{exp} \Bigl\{ -\frac{1}{2} \begin{bmatrix} \Phi^{-1}(u_1) \cdots \Phi^{-1}(u_n) \end{bmatrix}(\boldsymbol{P}^{-1} - \boldsymbol{I}_{nxn}) \begin{bmatrix} \Phi^{-1}(u_1) \\ \vdots \\ \Phi^{-1}(u_n) \end{bmatrix}  \Bigr\}$$

```{r}
library(copula)
gaussian_copula <- normalCopula(dim = 2)
gaussian_copula_fit <- fitCopula(gaussian_copula, uniform_df)
print(gaussian_copula_fit)
```

```{r}
rhog <- coef(gaussian_copula_fit)[1]
persp(normalCopula(dim=2,rhog),dCopula)
```

```{r}
ug <- rCopula(nrow(uniform_df),normalCopula(dim=2,rhog))
scatter_plot <- ggplot(uniform_df, aes(x = ipca_uniform, y = igpm_uniform)) +
  geom_point() +
  labs(title = "Gráfico de Dispersão", x = "ipca", y = "igpm")
scatter_plot <- scatter_plot +
  geom_point(data = as.data.frame(ug), aes(x = ug[,1], y = ug[,2]), color = 'blue', size = 1, alpha = 0.5)

print(scatter_plot)

```

**Student's t Copula** ​ A copula T é definida com $\boldsymbol{P}$ que é a matriz de correlação e $\nu$ graus de liberdade. ​ $$C(u_1,\ldots,u_n) = \boldsymbol{T}_{\boldsymbol{P}, \nu}(t^{-1}_{\nu}(u_1),\ldots,t^{-1}_{\nu}(u_n))$$ ​ $$c(u_1,\ldots,u_n) = \frac{\Gamma(\frac{\nu}{2})^{n-1} \Gamma(\frac{\nu+n}{2}) (1+\frac{1}{\nu} \begin{bmatrix} t_{\nu}^{-1}(u_1) \cdots t_{\nu}^{-1}(u_n) \end{bmatrix}\boldsymbol{P}^{-1} \begin{bmatrix} t_{\nu}^{-1}(u_1) \\ \vdots \\ t_{\nu}^{-1}(u_n) \end{bmatrix})^{-\frac{\nu+n}{2}}}{\Gamma(\frac{\nu + 1}{2})^n \sqrt{\textrm{det}(\boldsymbol{P})} \prod_{i=1}^n (1 + \frac{1}{\nu} (t^{-1}_{\nu}(u_i))^2)^{-\frac{\nu+1}{2}}}$$

```{r}
tstudent_copula <- tCopula(dim = 2)
tstudent_copula_fit <- fitCopula(tstudent_copula, uniform_df)
print(tstudent_copula_fit)

```

```{r}
rho <- coef(tstudent_copula_fit)[1]
df <- coef(tstudent_copula_fit)[2]
persp(tCopula(dim=2,rho,df=df),dCopula)
```

```{r}
u <- rCopula(nrow(uniform_df),tCopula(dim=2,rho,df=df))
# Plotar o gráfico de dispersão dos seus dados
scatter_plot <- ggplot(uniform_df, aes(x = ipca_uniform, y = igpm_uniform)) +
  geom_point(size=1) +
  labs(title = "Gráfico de Dispersão", x = "Ipca", y = "Igpm")

# Adicionar os pontos gerados a partir da cópula t-Student ao gráfico de dispersão
scatter_plot <- scatter_plot +
  geom_point(data = as.data.frame(u), aes(x = u[,1], y = u[,2]), color = 'blue', size = 1, alpha = 0.5)

# Exibir o gráfico combinado
print(scatter_plot)

```

**Copula Clayton**

$$C(u1, u2) = (\textrm{max}\{u_1^{-\theta} + u_2^{-\theta} -1, 0\})^{-\frac{1}{\theta}}$$

$$c(u1, u2) = (1+\theta)(u_1 u_2)^{-1-\theta}(-1 + u_1^{-\theta} + u_2^{-\theta})^{-2-\frac{1}{\theta}}$$ Onde $\theta$ é o grau de liberdade.

```{r}
clayton_copula <- claytonCopula(dim = 2)
clayton_copula_fit <- fitCopula(clayton_copula, uniform_df)
print(clayton_copula_fit)
```

```{r}
alpha <- coef(clayton_copula_fit)[1]
persp(claytonCopula(dim=2,alpha),dCopula)
```

```{r}
uc <- rCopula(nrow(uniform_df),claytonCopula(dim=2,alpha))
scatter_plot <- ggplot(uniform_df, aes(x = ipca_uniform, y = igpm_uniform)) +
  geom_point() +
  labs(title = "Gráfico de Dispersão", x = "Ipca", y = "Igpm")
scatter_plot <- scatter_plot +
  geom_point(data = as.data.frame(uc), aes(x = uc[,1], y = uc[,2]), color = 'blue', size = 1, alpha = 0.5)
print(scatter_plot)
```

**Frank Copula**

$$C(u_1, u_2) = -\frac{1}{\theta} \textrm{ln}(1 + \frac{(e^{-\theta u_1}-1)(e^{-\theta u_2}-1)}{e^{-\theta}-1})$$

$$c(u_1, u_2) = \frac{\theta e^{-\theta(u_1 + u_2)}(1-e^{-\theta})}{((1-e^{-\theta}) + (1-e^{-\theta u_1})(1-e^{-\theta u_2}))^2}$$ Onde $\theta$ é o grau de liberdade.

```{r}
frank_copula <- frankCopula(dim = 2)
frank_copula_fit <- fitCopula(frank_copula, uniform_df)
print(frank_copula_fit)

```

```{r}
alphaf <- coef(frank_copula_fit)[1]
persp(frankCopula(dim=2,alphaf),dCopula)
```

```{r}
uf <- rCopula(nrow(uniform_df),frankCopula(dim=2,alphaf))

scatter_plot <- ggplot(uniform_df, aes(x = ipca_uniform, y = igpm_uniform)) +
  geom_point() +
  labs(title = "Gráfico de Dispersão", x = "Ipca", y = "Igpm")

scatter_plot <- scatter_plot +
  geom_point(data = as.data.frame(uf), aes(x = uf[,1], y = uf[,2]), color = 'blue', size = 1, alpha = 0.5)

print(scatter_plot)
```

**Gumbel Copula**

$$C(u_1, u_2) = \textrm{exp} \{ -((-\ln(u_1))^{\theta} + (-\ln(u_2))^{\theta})^{\frac{1}{\theta}} \}$$

$$c(u_1, u_2) = \frac{\textrm{exp} \{ -((-\ln(u_1))^{\theta} + (-\ln(u_2))^{\theta})^{\frac{1}{\theta}} \}}{u_1 u_2}
                \frac{((-\ln(u_1))^{\theta} + (-\ln(u_2))^{\theta})^{\frac{2}{\theta}-2}}{(\ln(u_1)\ln(u_2)^{1-\theta})}
                (1+(\theta -1 )((-\ln(u_1))^{\theta} + (-\ln(u_2))^{\theta})^{-\frac{1}{\theta}})$$

Onde $\theta$ é o grau de liberdade.

```{r}
gumbel_copula <- gumbelCopula(dim = 2)
gumbel_copula_fit <- fitCopula(gumbel_copula, uniform_df)
print(gumbel_copula_fit)
```

```{r}
alphag <- coef(gumbel_copula_fit)[1]
persp(gumbelCopula(dim=2,alphag),dCopula)
```

```{r}
ug <- rCopula(nrow(uniform_df),gumbelCopula(dim=2,alphaf))
scatter_plot <- ggplot(uniform_df, aes(x = ipca_uniform, y = igpm_uniform)) +
  geom_point() +
  labs(title = "Gráfico de Dispersão", x = "Ipca", y = "Igpm")
scatter_plot <- scatter_plot +
  geom_point(data = as.data.frame(ug), aes(x = ug[,1], y = ug[,2]), color = 'blue', size = 1, alpha = 0.5)
print(scatter_plot)
```

```{r}
likelihoods <- c(
  gaussian = logLik(gaussian_copula_fit),
  student = logLik(tstudent_copula_fit),
  clayton = logLik(clayton_copula_fit),
  frank = logLik(frank_copula_fit),
  gumbel = logLik(gumbel_copula_fit)
)

likelihood_table <- data.frame(
  Copula = names(likelihoods),
  Log_Likelihood = likelihoods
)

print(likelihood_table)

```

**Aplicação:**

Agora vamos aplicar uma comparação de uma regressão feita atráves de cópulas e uma feita por MQO.

A regressão por compulas é feita pelo pacote "copulareg", A função ajusta distribuições conjuntas com uma estrutura de copula de pares R-vine, que é construída de forma que a densidade condicional e a distribuição de y possam ser calculadas explicitamente.

Uma Vine-Cópula é uma estrutura de copulas que permite calcular a distribuição conjunta atráves de pares de cópulas, onde seria possivel fazer "copula de copulas", permitindo que relações mais complexas entre as variáves sejám encontradas e trabalhadas no modelo.

```{r}
data <- data[, c("ipca","igpm" ,"juroreal","dolar")]
```

```{r}
library(copulareg)
set.seed(1)
tr <- sample(c(TRUE, FALSE), nrow(data), TRUE, c(0.8, 0.20))
y_tr <- data$ipca[tr]
y_te <- data$ipca[!tr]
x_tr <- apply(data[tr, -1], 2, as.numeric)
x_te <- apply(data[!tr, -1], 2, as.numeric)
var_type_x <- apply(x_tr, 2,
                   function(x) if(length(unique(x)) > 10) "c" else "c")

md <- copulareg::copulareg(y_tr, x_tr, "c", var_type_x)
pred_copula <- predict(md, new_x = x_te)

modelo_regressao <- lm(ipca ~ +juroreal + dolar + igpm, data = data[tr,])
pred_regressao <- predict(modelo_regressao, newdata = data[!tr, -1])

```

```{r}
# Criar o plot
plot(y_te, col = "black", type = "b", pch = 16, ylim = range(c(y_te, pred_copula, pred_regressao)), 
     main = "Comparação das Previsões dos Modelos com Valores Reais", 
     xlab = "Índice", ylab = "Valores")
lines(pred_copula, col = "red", type = "b", pch = 16)
lines(pred_regressao, col = "blue", type = "b", pch = 16)
legend("topright", legend = c("Valores Reais", "Modelo de Copula", "Modelo de Regressão Linear"), 
       col = c("black", "red", "blue"), pch = 16, lty = 1, cex = 0.8)
```

```{r}
mse_copula <- mean((pred_copula - y_te)^2)
cat("Erro Quadrático Médio do Modelo de Copula:", mse_copula, "\n")
mse_regressao <- mean((pred_regressao - y_te)^2)
cat("Erro Quadrático Médio do Modelo de Regressão Linear:", mse_regressao, "\n")
```

***Referências :***

1)  Nelsen, R. (1999). An Introduction to Copulas, 2nd ed. Springer, New York.

2)  Fisher, N.I. (1997), Copulas, in Encyclopedia of Statistical Sciences. Update Vol.1

3)  Mukhopadhyay, S. Parzen, E. (2019), Nonparametric Universal Copula Modeling. Applied Stochastic Models in Business and Industry,

4)  Krämer, N., Brechmann, E. C., Silvestrini, D., & Czado.(2013) Total loss estimation using copula-based regression models. Insurance: Mathematics and Economics.
